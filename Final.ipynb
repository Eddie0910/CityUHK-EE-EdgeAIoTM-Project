{"cells":[{"cell_type":"markdown","id":"c21f584a","metadata":{"id":"c21f584a"},"source":["# First Connect to the Wifi"]},{"cell_type":"code","execution_count":null,"id":"a93d125f","metadata":{"id":"a93d125f"},"outputs":[],"source":["from pynq.lib import Wifi\n","port = Wifi()"]},{"cell_type":"code","execution_count":null,"id":"b22b2a1d","metadata":{"id":"b22b2a1d"},"outputs":[],"source":["ssid = ###\n","pwd = ###\n","port.connect(ssid, pwd, auto=True, force=True)"]},{"cell_type":"code","execution_count":null,"id":"42178110","metadata":{"id":"42178110"},"outputs":[],"source":["! ping -I wlan0 www.yahoo.com -c 5"]},{"cell_type":"markdown","id":"35989874","metadata":{"id":"35989874"},"source":["# Set up Object Classification"]},{"cell_type":"code","execution_count":null,"id":"8078534d","metadata":{"id":"8078534d"},"outputs":[],"source":["from pynq_dpu import DpuOverlay\n","overlay = DpuOverlay(\"/home/xilinx/DPU-PYNQ-3.5/dpu.bit\")"]},{"cell_type":"code","execution_count":null,"id":"fc03893d","metadata":{"id":"fc03893d"},"outputs":[],"source":["overlay?"]},{"cell_type":"code","execution_count":null,"id":"36601eef","metadata":{"id":"36601eef"},"outputs":[],"source":["import os\n","import time\n","import numpy as np\n","import cv2\n","import random\n","import colorsys\n","from matplotlib.patches import Rectangle\n","import matplotlib.pyplot as plt\n","%matplotlib inline"]},{"cell_type":"code","execution_count":null,"id":"e76e8976","metadata":{"id":"e76e8976"},"outputs":[],"source":["overlay.load_model(\"/home/xilinx/DPU-PYNQ-3.5/tf_yolov3_3.5.xmodel\")"]},{"cell_type":"code","execution_count":null,"id":"ede83d34","metadata":{"id":"ede83d34"},"outputs":[],"source":["anchor_list = [10,13,16,30,33,23,30,61,62,45,59,119,116,90,156,198,373,326]\n","anchor_float = [float(x) for x in anchor_list]\n","anchors = np.array(anchor_float).reshape(-1, 2)"]},{"cell_type":"code","execution_count":null,"id":"0108655d","metadata":{"id":"0108655d"},"outputs":[],"source":["'''Get model classification information'''\n","def get_class(classes_path):\n","    with open(classes_path) as f:\n","        class_names = f.readlines()\n","    class_names = [c.strip() for c in class_names]\n","    return class_names\n","\n","classes_path = \"pynq_dpu/img/voc_classes.txt\"\n","class_names = get_class(classes_path)"]},{"cell_type":"code","execution_count":null,"id":"781de9d8","metadata":{"id":"781de9d8"},"outputs":[],"source":["num_classes = len(class_names)\n","hsv_tuples = [(1.0 * x / num_classes, 1., 1.) for x in range(num_classes)]\n","colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n","colors = list(map(lambda x:\n","                  (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)),\n","                  colors))\n","random.seed(0)\n","random.shuffle(colors)\n","random.seed(None)"]},{"cell_type":"code","execution_count":null,"id":"1244b699","metadata":{"id":"1244b699"},"outputs":[],"source":["def letterbox_image(image, size):\n","    ih, iw, _ = image.shape\n","    w, h = size\n","    scale = min(w/iw, h/ih)\n","    #print(scale)\n","\n","    nw = int(iw*scale)\n","    nh = int(ih*scale)\n","    #print(nw)\n","    #print(nh)\n","\n","    image = cv2.resize(image, (nw,nh), interpolation=cv2.INTER_LINEAR)\n","    new_image = np.ones((h,w,3), np.uint8) * 128\n","    h_start = (h-nh)//2\n","    w_start = (w-nw)//2\n","    new_image[h_start:h_start+nh, w_start:w_start+nw, :] = image\n","    return new_image\n","\n","\n","'''image preprocessing'''\n","def pre_process(image, model_image_size):\n","    image = image[...,::-1]\n","    image_h, image_w, _ = image.shape\n","\n","    if model_image_size != (None, None):\n","        assert model_image_size[0]%32 == 0, 'Multiples of 32 required'\n","        assert model_image_size[1]%32 == 0, 'Multiples of 32 required'\n","        boxed_image = letterbox_image(image, tuple(reversed(model_image_size)))\n","    else:\n","        new_image_size = (image_w - (image_w % 32), image_h - (image_h % 32))\n","        boxed_image = letterbox_image(image, new_image_size)\n","    image_data = np.array(boxed_image, dtype='float32')\n","    image_data /= 255.\n","    image_data = np.expand_dims(image_data, 0)\n","    return image_data"]},{"cell_type":"code","execution_count":null,"id":"95abe6e0","metadata":{"id":"95abe6e0"},"outputs":[],"source":["def _get_feats(feats, anchors, num_classes, input_shape):\n","    num_anchors = len(anchors)\n","    anchors_tensor = np.reshape(np.array(anchors, dtype=np.float32), [1, 1, 1, num_anchors, 2])\n","    grid_size = np.shape(feats)[1:3]\n","    nu = num_classes + 5\n","    predictions = np.reshape(feats, [-1, grid_size[0], grid_size[1], num_anchors, nu])\n","    grid_y = np.tile(np.reshape(np.arange(grid_size[0]), [-1, 1, 1, 1]), [1, grid_size[1], 1, 1])\n","    grid_x = np.tile(np.reshape(np.arange(grid_size[1]), [1, -1, 1, 1]), [grid_size[0], 1, 1, 1])\n","    grid = np.concatenate([grid_x, grid_y], axis = -1)\n","    grid = np.array(grid, dtype=np.float32)\n","\n","    box_xy = (1/(1+np.exp(-predictions[..., :2])) + grid) / np.array(grid_size[::-1], dtype=np.float32)\n","    box_wh = np.exp(predictions[..., 2:4]) * anchors_tensor / np.array(input_shape[::-1], dtype=np.float32)\n","    box_confidence = 1/(1+np.exp(-predictions[..., 4:5]))\n","    box_class_probs = 1/(1+np.exp(-predictions[..., 5:]))\n","    return box_xy, box_wh, box_confidence, box_class_probs\n","\n","\n","def correct_boxes(box_xy, box_wh, input_shape, image_shape):\n","    box_yx = box_xy[..., ::-1]\n","    box_hw = box_wh[..., ::-1]\n","    input_shape = np.array(input_shape, dtype = np.float32)\n","    image_shape = np.array(image_shape, dtype = np.float32)\n","    new_shape = np.around(image_shape * np.min(input_shape / image_shape))\n","    offset = (input_shape - new_shape) / 2. / input_shape\n","    scale = input_shape / new_shape\n","    box_yx = (box_yx - offset) * scale\n","    box_hw *= scale\n","\n","    box_mins = box_yx - (box_hw / 2.)\n","    box_maxes = box_yx + (box_hw / 2.)\n","    boxes = np.concatenate([\n","        box_mins[..., 0:1],\n","        box_mins[..., 1:2],\n","        box_maxes[..., 0:1],\n","        box_maxes[..., 1:2]\n","    ], axis = -1)\n","    boxes *= np.concatenate([image_shape, image_shape], axis = -1)\n","    return boxes\n","\n","\n","def boxes_and_scores(feats, anchors, classes_num, input_shape, image_shape):\n","    box_xy, box_wh, box_confidence, box_class_probs = _get_feats(feats, anchors, classes_num, input_shape)\n","    boxes = correct_boxes(box_xy, box_wh, input_shape, image_shape)\n","    boxes = np.reshape(boxes, [-1, 4])\n","    box_scores = box_confidence * box_class_probs\n","    box_scores = np.reshape(box_scores, [-1, classes_num])\n","    return boxes, box_scores"]},{"cell_type":"code","execution_count":null,"id":"e2333213","metadata":{"id":"e2333213"},"outputs":[],"source":["'''Draw detection frame'''\n","def draw_bbox(image, bboxes, classes):\n","    \"\"\"\n","    bboxes: [x_min, y_min, x_max, y_max, probability, cls_id] format coordinates.\n","    \"\"\"\n","    num_classes = len(classes)\n","    image_h, image_w, _ = image.shape\n","    hsv_tuples = [(1.0 * x / num_classes, 1., 1.) for x in range(num_classes)]\n","    colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n","    colors = list(map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)), colors))\n","\n","    random.seed(0)\n","    random.shuffle(colors)\n","    random.seed(None)\n","\n","    for i, bbox in enumerate(bboxes):\n","        coor = np.array(bbox[:4], dtype=np.int32)\n","        fontScale = 0.5\n","        score = bbox[4]\n","        class_ind = int(bbox[5])\n","        bbox_color = colors[class_ind]\n","        bbox_thick = int(0.6 * (image_h + image_w) / 600)\n","        c1, c2 = (coor[0], coor[1]), (coor[2], coor[3])\n","        cv2.rectangle(image, c1, c2, bbox_color, bbox_thick)\n","    return image\n","\n","\n","def nms_boxes(boxes, scores):\n","    \"\"\"Suppress non-maximal boxes.\n","\n","    # Arguments\n","        boxes: ndarray, boxes of objects.\n","        scores: ndarray, scores of objects.\n","\n","    # Returns\n","        keep: ndarray, index of effective boxes.\n","    \"\"\"\n","    x1 = boxes[:, 0]\n","    y1 = boxes[:, 1]\n","    x2 = boxes[:, 2]\n","    y2 = boxes[:, 3]\n","\n","    areas = (x2-x1+1)*(y2-y1+1)\n","    order = scores.argsort()[::-1]\n","\n","    keep = []\n","    while order.size > 0:\n","        i = order[0]\n","        keep.append(i)\n","\n","        xx1 = np.maximum(x1[i], x1[order[1:]])\n","        yy1 = np.maximum(y1[i], y1[order[1:]])\n","        xx2 = np.minimum(x2[i], x2[order[1:]])\n","        yy2 = np.minimum(y2[i], y2[order[1:]])\n","\n","        w1 = np.maximum(0.0, xx2 - xx1 + 1)\n","        h1 = np.maximum(0.0, yy2 - yy1 + 1)\n","        inter = w1 * h1\n","\n","        ovr = inter / (areas[i] + areas[order[1:]] - inter)\n","        inds = np.where(ovr <= 0.55)[0]  # threshold\n","        order = order[inds + 1]\n","\n","    return keep"]},{"cell_type":"code","execution_count":null,"id":"f37b165a","metadata":{"id":"f37b165a"},"outputs":[],"source":["def draw_boxes(image, boxes, scores, classes):\n","    _, ax = plt.subplots(1)\n","    ax.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n","    image_h, image_w, _ = image.shape\n","\n","    for i, bbox in enumerate(boxes):\n","        [top, left, bottom, right] = bbox\n","        width, height = right - left, bottom - top\n","        center_x, center_y = left + width*0.5, top + height*0.5\n","        score, class_index = scores[i], classes[i]\n","        label = '{}: {:.4f}'.format(class_names[class_index], score)\n","        color = tuple([color/255 for color in colors[class_index]])\n","        ax.add_patch(Rectangle((left, top), width, height,\n","                               edgecolor=color, facecolor='none'))\n","        ax.annotate(label, (center_x, center_y), color=color, weight='bold',\n","                    fontsize=12, ha='center', va='center')\n","    return ax"]},{"cell_type":"code","execution_count":null,"id":"340df633","metadata":{"id":"340df633"},"outputs":[],"source":["def evaluate(yolo_outputs, image_shape, class_names, anchors):\n","    score_thresh = 0.2\n","    anchor_mask = [[6, 7, 8], [3, 4, 5], [0, 1, 2]]\n","    boxes = []\n","    box_scores = []\n","    input_shape = np.shape(yolo_outputs[0])[1 : 3]\n","    input_shape = np.array(input_shape)*32\n","\n","    for i in range(len(yolo_outputs)):\n","        _boxes, _box_scores = boxes_and_scores(\n","            yolo_outputs[i], anchors[anchor_mask[i]], len(class_names),\n","            input_shape, image_shape)\n","        boxes.append(_boxes)\n","        box_scores.append(_box_scores)\n","    boxes = np.concatenate(boxes, axis = 0)\n","    box_scores = np.concatenate(box_scores, axis = 0)\n","\n","    mask = box_scores >= score_thresh\n","    boxes_ = []\n","    scores_ = []\n","    classes_ = []\n","    for c in range(len(class_names)):\n","        class_boxes_np = boxes[mask[:, c]]\n","        class_box_scores_np = box_scores[:, c]\n","        class_box_scores_np = class_box_scores_np[mask[:, c]]\n","        nms_index_np = nms_boxes(class_boxes_np, class_box_scores_np)\n","        class_boxes_np = class_boxes_np[nms_index_np]\n","        class_box_scores_np = class_box_scores_np[nms_index_np]\n","        classes_np = np.ones_like(class_box_scores_np, dtype = np.int32) * c\n","        boxes_.append(class_boxes_np)\n","        scores_.append(class_box_scores_np)\n","        classes_.append(classes_np)\n","    boxes_ = np.concatenate(boxes_, axis = 0)\n","    scores_ = np.concatenate(scores_, axis = 0)\n","    classes_ = np.concatenate(classes_, axis = 0)\n","\n","    return boxes_, scores_, classes_"]},{"cell_type":"markdown","id":"642c3ff8","metadata":{"id":"642c3ff8"},"source":["## Use Vart"]},{"cell_type":"code","execution_count":null,"id":"97643773","metadata":{"id":"97643773"},"outputs":[],"source":["dpu = overlay.runner"]},{"cell_type":"code","execution_count":null,"id":"41fef043","metadata":{"id":"41fef043"},"outputs":[],"source":["inputTensors = dpu.get_input_tensors()"]},{"cell_type":"code","execution_count":null,"id":"bad4b545","metadata":{"id":"bad4b545"},"outputs":[],"source":["outputTensors = dpu.get_output_tensors()"]},{"cell_type":"code","execution_count":null,"id":"e546cb5e","metadata":{"id":"e546cb5e"},"outputs":[],"source":["shapeIn = tuple(inputTensors[0].dims)"]},{"cell_type":"code","execution_count":null,"id":"2a7e4a83","metadata":{"id":"2a7e4a83"},"outputs":[],"source":["shapeOut0 = (tuple(outputTensors[0].dims)) # (1, 13, 13, 75)\n","shapeOut1 = (tuple(outputTensors[1].dims)) # (1, 26, 26, 75)\n","shapeOut2 = (tuple(outputTensors[2].dims)) # (1, 52, 52, 75)"]},{"cell_type":"code","execution_count":null,"id":"b4c2f0a4","metadata":{"id":"b4c2f0a4"},"outputs":[],"source":["outputSize0 = int(outputTensors[0].get_data_size() / shapeIn[0]) # 12675\n","outputSize1 = int(outputTensors[1].get_data_size() / shapeIn[0]) # 50700\n","outputSize2 = int(outputTensors[2].get_data_size() / shapeIn[0]) # 202800"]},{"cell_type":"code","execution_count":null,"id":"afb41222","metadata":{"id":"afb41222"},"outputs":[],"source":["input_data = [np.empty(shapeIn, dtype=np.float32, order=\"C\")]\n","output_data = [np.empty(shapeOut0, dtype=np.float32, order=\"C\"),\n","               np.empty(shapeOut1, dtype=np.float32, order=\"C\"),\n","               np.empty(shapeOut2, dtype=np.float32, order=\"C\")]\n","image = input_data[0]"]},{"cell_type":"code","execution_count":null,"id":"b1645d66","metadata":{"id":"b1645d66"},"outputs":[],"source":["def run2(display = False):\n","    orig_img_path = 'Data/test.png'\n","\n","    # Read input image\n","    input_image = cv2.imread(orig_img_path)\n","\n","    # Pre-processing\n","    image_size = input_image.shape[:2]\n","    image_data = np.array(pre_process(input_image, (416, 416)), dtype=np.float32)\n","\n","    # Fetch data to DPU and trigger it\n","    image[0,...] = image_data.reshape(shapeIn[1:])\n","    job_id = dpu.execute_async(input_data, output_data)\n","    dpu.wait(job_id)\n","\n","    # Retrieve output data\n","    conv_out0 = np.reshape(output_data[0], shapeOut0)\n","    conv_out1 = np.reshape(output_data[1], shapeOut1)\n","    conv_out2 = np.reshape(output_data[2], shapeOut2)\n","    yolo_outputs = [conv_out0, conv_out1, conv_out2]\n","\n","    # Decode output from YOLOv3\n","    boxes, scores, classes = evaluate(yolo_outputs, image_size, class_names, anchors)\n","\n","    if display:\n","        _ = draw_boxes(input_image, boxes, scores, classes)\n","    print(\"Number of detected objects: {}\".format(len(boxes)))\n","\n","    objectsDetected = []\n","    for i, bbox in enumerate(boxes):\n","        class_index = classes[i]\n","        objectsDetected.append(class_names[class_index])\n","    return(objectsDetected[0])"]},{"cell_type":"markdown","id":"0e37f5b2","metadata":{"id":"0e37f5b2"},"source":["# Display to Adafruit IO through internet"]},{"cell_type":"code","execution_count":null,"id":"7acda151","metadata":{"id":"7acda151"},"outputs":[],"source":["from pynq import GPIO\n","from time import sleep\n","from Adafruit_IO import MQTTClient\n","from Adafruit_IO import Client\n","\n","ADAFRUIT_IO_USERNAME = ###\n","ADAFRUIT_IO_KEY = ###"]},{"cell_type":"code","execution_count":null,"id":"6babd179","metadata":{"id":"6babd179"},"outputs":[],"source":["boxFeed1 = \"stored-object\"\n","boxFeed2 = \"stored-object-2\"\n","boxFeed3 = \"stored-object-3\"\n","retrieveFeed = \"delete1\"\n","scheduleFeed = \"time\"\n","newObjectFeed = \"detect\"\n","openBoxFeed = \"open-box\"\n","imageFeed = \"stored-image\"\n","getImageFeed = \"get-image\""]},{"cell_type":"code","execution_count":null,"id":"1841a7f0","metadata":{"id":"1841a7f0"},"outputs":[],"source":["def connected(client):\n","    print(\"Connected to Adafruit IO!\")\n","    client.subscribe(boxFeed1)\n","    client.subscribe(boxFeed2)\n","    client.subscribe(boxFeed2)\n","    client.subscribe(retrieveFeed)\n","    client.subscribe(scheduleFeed)\n","    client.subscribe(newObjectFeed)\n","    client.subscribe(openBoxFeed)\n","    client.subscribe(imageFeed)\n","    client.subscribe(getImageFeed)\n","\n","def message(client, feed_id, payload):\n","    print(f\"Received: {feed_id} {payload}\")\n","\n","client = MQTTClient(ADAFRUIT_IO_USERNAME, ADAFRUIT_IO_KEY)\n","aio = Client(ADAFRUIT_IO_USERNAME, ADAFRUIT_IO_KEY)\n","client.on_connect = connected\n","client.on_message = message"]},{"cell_type":"markdown","id":"fc4eb4f4","metadata":{"id":"fc4eb4f4"},"source":["# Open Camera for Video Streaming"]},{"cell_type":"code","execution_count":null,"id":"769a9a86","metadata":{"scrolled":false,"id":"769a9a86"},"outputs":[],"source":["import cv2\n","\n","camera = cv2.VideoCapture(0)\n","\n","width = int(camera.get(cv2.CAP_PROP_FRAME_WIDTH))\n","height = int(camera.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","camera.set(cv2.CAP_PROP_FRAME_WIDTH,width)\n","camera.set(cv2.CAP_PROP_FRAME_HEIGHT,height)"]},{"cell_type":"code","execution_count":null,"id":"69548add","metadata":{"id":"69548add"},"outputs":[],"source":["import IPython\n","\n","def imshow(img):\n","    returnValue, buffer = cv2.imencode('.jpg', img)\n","    IPython.display.display(IPython.display.Image(data=buffer.tobytes()))"]},{"cell_type":"markdown","id":"280849f9","metadata":{"id":"280849f9"},"source":["# Main Loop"]},{"cell_type":"code","execution_count":null,"id":"5918bb29","metadata":{"id":"5918bb29"},"outputs":[],"source":["# Declare Variables used in the main loop\n","from datetime import datetime\n","from PIL import Image as PIL_Image\n","from zoneinfo import ZoneInfo\n","import base64\n","\n","boxObjects1, boxObjects2, boxObjects3 = [], [], []\n","scheduledTime = [] # in the form of [DD/MM, hh:mm, n, i]\n","i = 0\n","boxNumber = \"\"\n","objectIndex = \"\"\n","timeofDay = \"\"\n","Date = \"\"\n","newSchedule = \"\"\n","newRetrieval = \"\"\n","totalCount = 0"]},{"cell_type":"code","execution_count":null,"id":"83ce593a","metadata":{"id":"83ce593a"},"outputs":[],"source":["def updateBox(N):\n","    output = \"\"\n","    if (N == 1):\n","        if (len (boxObjects1) == 0):\n","            aio.send_data(boxFeed1, \"0\")\n","        else:\n","            for i in (range(len(boxObjects1))):\n","                output += f\"{i + 1}: {boxObjects1[i][0]}\\n\"\n","            aio.send_data(boxFeed1, output)\n","    elif (N == 2):\n","        if (len (boxObjects2) == 0):\n","            aio.send_data(boxFeed2, \"0\")\n","        else:\n","            for i in (range(len(boxObjects2))):\n","                output += f\"{i + 1}: {boxObjects2[i][0]}\\n\"\n","            aio.send_data(boxFeed2, output)\n","    elif (N == 3):\n","        if (len (boxObjects3) == 0):\n","            aio.send_data(boxFeed3, \"0\")\n","        else:\n","            for i in (range(len(boxObjects3))):\n","                output += f\"{i + 1}: {boxObjects3[i][0]}\\n\"\n","            aio.send_data(boxFeed3, output)\n"]},{"cell_type":"code","execution_count":null,"id":"5a70bcf1","metadata":{"id":"5a70bcf1"},"outputs":[],"source":["def doRetrieve(boxNumber, objectIndex): # base index = 1, strings\n","    if (boxNumber == '1'):\n","        del(boxObjects1[int(objectIndex) - 1])\n","    if (boxNumber == '2'):\n","        del(boxObjects2[int(objectIndex) - 1])\n","    if (boxNumber == '3'):\n","        del(boxObjects3[int(objectIndex) - 1])\n","    updateBox(int(boxNumber))\n","    aio.send_data(openBoxFeed, int(boxNumber))"]},{"cell_type":"markdown","id":"592538a1","metadata":{"id":"592538a1"},"source":["# Initialisation"]},{"cell_type":"code","execution_count":null,"id":"13b1e84b","metadata":{"scrolled":true,"id":"13b1e84b"},"outputs":[],"source":["for i in range (1, 4):\n","    updateBox(i)\n","\n","aio.send_data(retrieveFeed, \"0\")\n","aio.send_data(scheduleFeed, \"0\")\n","aio.send_data(newObjectFeed, \"0\")\n","aio.send_data(openBoxFeed, \"0\")\n","aio.send_data(imageFeed, \"0\")\n","aio.send_data(getImageFeed, \"0\")"]},{"cell_type":"code","execution_count":null,"id":"079b55c0","metadata":{"scrolled":true,"id":"079b55c0"},"outputs":[],"source":["while True:\n","    i = int(aio.receive(newObjectFeed).value)\n","    if (i):\n","        num_frames = 40\n","        for _ in range(num_frames):\n","        # Capture frame-by-frame\n","            ret, frame_in = camera.read()\n","            if (not ret):\n","                # Release the Video Device if ret is false\n","                camera.release()\n","                # Message to be displayed after releasing the device\n","                print(\"Release camera resource\")\n","                break\n","            imshow(frame_in)\n","            IPython.display.clear_output(wait=True)\n","        cv2.imwrite('Data/test.png', frame_in)\n","        result = run2(display=True)  # Using the photo for object detection\n","\n","        img = cv2.imread(\"Data/test.png\")\n","        resized_img = cv2.resize(img, (240, 180), interpolation=cv2.INTER_AREA) # Resize the taken photo to a smaller resolution for data transfer\n","        cv2.imwrite(\"Data/store.png\", resized_img)\n","        with open(\"Data/store.png\", \"rb\") as image_file:\n","            binary_data = image_file.read()\n","        encoded_bytes = base64.b64encode(binary_data)\n","        base64_string = encoded_bytes.decode(\"utf-8\") # Encode the photo into Base64 for passing to the Adafruit IO\n","\n","        boxObjects1.append([result, base64_string])  # Adding the object [object name, photo (base64)] to memory list\n","        updateBox(1)  # Updating the value shown on the Adafruit IO\n","        aio.send_data(openBoxFeed, 1)  # Tell the Arduino to open the box\n","        print(result)\n","        aio.send_data(newObjectFeed, 0)  # Resetting\n","\n","    newSchedule = aio.receive(scheduleFeed).value #See what time the user want to open (in the format of \"n i hh:mm DD/MM\")\n","    if (newSchedule != \"0\"):\n","        # If there is a scheduled time\n","        boxNumber, objectIndex, timeofDay, Date = newSchedule.split()\n","        scheduledTime.append([Date, timeofDay, boxNumber, objectIndex])\n","        scheduledTime.sort()  # Make it so that it sees which object should be taken first\n","        if (boxNumber == '1'):  # Update the box object information shown, adding the scheduled time\n","            boxObjects1[int(objectIndex) - 1][0] = boxObjects1[int(objectIndex) - 1][0] + f\" ({Date}, {timeofDay})\"\n","        elif (boxNumber == '2'):\n","            boxObjects2[int(objectIndex) - 1][0] = boxObjects2[int(objectIndex) - 1][0] + f\" ({Date}, {timeofDay})\"\n","        elif (boxNumber == '3'):\n","            boxObjects3[int(objectIndex) - 1][0] = boxObjects3[int(objectIndex) - 1][0] + f\" ({Date}, {timeofDay})\"\n","        updateBox(int(boxNumber))\n","        aio.send_data(scheduleFeed, \"0\")\n","        print(scheduledTime)\n","\n","    # if the time meets the schedule\n","    timeNow = datetime.now(ZoneInfo(\"Asia/Hong_Kong\")).strftime(\"%d/%m %H:%M\")\n","    while (len(scheduledTime) > 0 and timeNow >= (scheduledTime[0][0] + \" \" + scheduledTime[0][1])): # Checks if it has reached the time\n","        print(scheduledTime[0][0] + \" \" + scheduledTime[0][1])\n","        doRetrieve(scheduledTime[0][2], scheduledTime[0][3])\n","        del(scheduledTime[0])\n","\n","    newRetrieval = aio.receive(retrieveFeed).value # format = \"n i\"\n","    if (newRetrieval != \"0\"):\n","        # If there is a retrieval of an object\n","        boxNumber, objectIndex = newRetrieval.split()\n","        doRetrieve(boxNumber, objectIndex)\n","        aio.send_data(retrieveFeed, \"0\")\n","\n","    getImage = aio.receive(getImageFeed).value\n","    if (getImage != \"0\"):\n","        boxNumber, objectIndex = getImage.split()\n","        if (boxNumber == '1'):\n","            aio.send_data(imageFeed, boxObjects1[int(objectIndex) - 1][1]) # retrieve the base64 photo stored in the list\n","        if (boxNumber == '2'):\n","            aio.send_data(imageFeed, boxObjects2[int(objectIndex) - 1][1])\n","        if (boxNumber == '3'):\n","            aio.send_data(imageFeed, boxObjects3[int(objectIndex) - 1][1])\n","        aio.send_data(getImageFeed, \"0\")"]},{"cell_type":"code","execution_count":null,"id":"24115816","metadata":{"scrolled":true,"id":"24115816"},"outputs":[],"source":["camera.release()"]},{"cell_type":"code","execution_count":null,"id":"52a77e26","metadata":{"id":"52a77e26"},"outputs":[],"source":["del overlay\n","del dpu"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}